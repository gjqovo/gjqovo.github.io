---
layout: post
author: Gjq
title: "HDFS概述"
date: 2024-01-21 16:15:45 +0800
categories: [learn Hadoop HDFS]
tags: [Learn Hadoop HDFS]
---

# HDFS

## 简介

### 产出背景

HDFS（Hadoop Distributed File System），它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。

HDFS 的使用场景：适合一次写入，多次读出的场景。一个文件经过创建、写入和关闭之后就不需要改变。

### HDFS优点

- 高容错性

    数据自动保存多个副本，当某个副本丢失时，可以自动恢复

- 处理大数据

    数据规模大，TB,PB
    文件规模大，数百万文件

- 可以构建在廉价的机器上

### HDFS缺点

- 不适合低延时数据访问

- 无法高效地对大量小文件进行存储

    ➢ 存储大量小文件的话，它会占用NameNode大量的内存来存储文件目录和块信息（每个150字节）。这样是不可取的，因为NameNode的内存（128G）总是有限的;</br>
    ➢ 小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。

- 不支持并发写入、文件随机修改

    ➢ 一个文件只能有一个写，不允许多个线程同时写；</br>
    ➢ 仅支持数据append（追加），不支持文件的随机修改

### HDFS组成架构

1. NameNode（nn）：就是Master，它是一个主管、管理者。

    - 管理HDFS的名称空间；
    - 配置副本策略；
    - 管理数据块（Block）映射信息；
    - 处理客户端读写请求。

2. DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。

    - 存储实际的数据块；
    - 执行数据块的读/写操作。

3. Client：就是客户端。

    - 文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传；
    - 与NameNode交互，获取文件的位置信息；
    - 与DataNode交互，读取或者写入数据；
    - Client提供一些命令来管理HDFS，比如NameNode格式化；
    - Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作；

4. Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。

    - 辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode ；
    - 在紧急情况下，可辅助恢复NameNode。

### HDFS文件块大小

HDFS中的文件在物理上是分块存储（Block），块的大小可以通过配置参数（dfs.blocksize）来规定，默认大小在Hadoop2.x/3.x版本中是128M，1.x版本中是64M。

1. 集群中的block
2. 如果寻址时间约为10ms，即查找到目标block的时间为10ms。
3. 寻址时间为传输时间的1%时，则为最佳状态。（专家）因此，传输时间=10ms/0.01=1000ms=1s
4. 而目前磁盘的传输速率普遍为100MB/s。
5. block size = 100MB/s * 1s = 100MB

Q: 为什么块的大小不能设置太小，也不能设置太大？

A:
    - HDFS的块设置太小，会增加寻址时间，程序一直在找块的开始位置；
    - 如果块设置的太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。导致程序在处理这块数据时，会非常慢。

总结：HDFS块的大小设置主要取决于磁盘传输速率。

## HDFS的Shell操作

### 基本语法

```shell
# hadoop fs
# hdfs dfs
```

### 命令大全

```shell
[admin@hadoop102 hadoop-3.1.3]$ hdfs dfs
Usage: hadoop fs [generic options]
        [-appendToFile <localsrc> ... <dst>]
        [-cat [-ignoreCrc] <src> ...]
        [-checksum <src> ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
        [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
        [-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
        [-createSnapshot <snapshotDir> [<snapshotName>]]
        [-deleteSnapshot <snapshotDir> <snapshotName>]
        [-df [-h] [<path> ...]]
        [-du [-s] [-h] [-v] [-x] <path> ...]
        [-expunge]
        [-find <path> ... <expression> ...]
        [-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-getfacl [-R] <path>]
        [-getfattr [-R] {-n name | -d} [-e en] <path>]
        [-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
        [-head <file>]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
        [-mkdir [-p] <path> ...]
        [-moveFromLocal <localsrc> ... <dst>]
        [-moveToLocal <src> <localdst>]
        [-mv <src> ... <dst>]
        [-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
        [-renameSnapshot <snapshotDir> <oldName> <newName>]
        [-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
        [-rmdir [--ignore-fail-on-non-empty] <dir> ...]
        [-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
        [-setfattr {-n name [-v value] | -x name} <path>]
        [-setrep [-R] [-w] <rep> <path> ...]
        [-stat [format] <path> ...]
        [-tail [-f] [-s <sleep interval>] <file>]
        [-test -[defsz] <path>]
        [-text [-ignoreCrc] <src> ...]
        [-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
        [-touchz <path> ...]
        [-truncate [-w] <length> <path> ...]
        [-usage [cmd ...]]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]
```

### 常用命令

#### 使用帮助

```shell
hdfs dfs -help rm
# hadoop fs -help rm
```

#### 上传

| 命令 | 含义 | 示例 |
|:---|:---|:---|
| -moveFromLocal | 从本地剪切粘贴到 HDFS | ` hadoop fs -moveFromLocal ./shuguo.txt /sanguo ` |
| -copyFromLocal | 从本地文件系统中拷贝文件到 HDFS 路径去 | ` hadoop fs -copyFromLocal weiguo.txt /sanguo ` |
| -put | 等同于 copyFromLocal，生产环境更习惯用 put |  ` hadoop fs -put ./wuguo.txt /sanguo ` |
| -appendToFile | 追加一个文件到已经存在的文件末尾 | ` hadoop fs -appendToFile liubei.txt /sanguo/shuguo.txt ` |

#### 下载

| 命令 | 含义 | 示例 |
|:---|:---|:---|
| -copyToLocal | 从 HDFS 拷贝到本地 | ` hadoop fs -copyToLocal sanguo/shuguo.txt ./ ` |
| -get | 等同于 copyToLocal，生产环境更习惯用 get | ` hadoop fs -copyToLocal sanguo/shuguo.txt ./shuguo2.txt ` |

#### HDFS直接操作

| 命令 | 含义 | 示例 |
|:---|:---|:---|
| -ls | 显示目录信息 | ` hadoop fs -ls /sanguo ` |
| -cat | |
| -chgrp -chmod -chown | 修改权限 ||
| -mkdir |||
| -cp | ||
| -mv |||
| -tail |||
| **-rm** *-rm -r* |||
| -du |||
| -setrep | 设置HDFS中文件的副本数量 | ` hadoop fs -setrep 10 /jinguo/shuguo.txt ` |

> TAG: -du

```shell
[admin@hadoop102 hadoop-3.1.3]$ hadoop fs -du -s -h /jinguo
27  172  /jinguo
[admin@hadoop102 hadoop-3.1.3]$ hadoop fs -du /jinguo
13  130  /jinguo/shuguo.txt
7   21   /jinguo/weiguo.txt
7   21   /jinguo/wuguo.txt
# fileSize fileSize*副本数
```

> Note: -setrep
>
> 这里设置的副本数只是记录在 NameNode 的元数据中，是否真的会有这么多副本，还得看 DataNode 的数量。因为目前只有 3 台设备，最多也就 3 个副本，只有节点数的增加到 10台时，副本数才能达到 10。

## HDFS的API操作

### 环境准备
